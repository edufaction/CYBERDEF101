{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de text 2 speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- essai de texte\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install webrtcvad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper DEBRUITEUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_wav=\"/Users/fcdw3504/Documents/GitHub/CYBERDEF101/Release/SEC101/Teacher/Lessons/Audionotes/sources/eric.wav\"\n",
    "debruit_wav=\"/Users/fcdw3504/Documents/GitHub/CYBERDEF101/Release/SEC101/Teacher/Lessons/Audionotes/sources/ericdebruit.wav\"\n",
    "\n",
    "! play $speaker_wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sox $speaker_wav $debruit_wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! play $debruit_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fcdw3504/Documents/GitHub/CYBERDEF101/Release/SEC101/Teacher/Lessons/Audionotes/sources/ericdebruit.wav\n",
      "/Users/fcdw3504/Documents/GitHub/CYBERDEF101/Release/SEC101/Teacher/Lessons/Audionotes/sources/eric.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "input_dir = \"/Users/fcdw3504/Documents/GitHub/CYBERDEF101/Release/SEC101/Teacher/Lessons/Audionotes/sources\"\n",
    "output_dir = \"/Users/fcdw3504/Documents/GitHub/CYBERDEF101/Release/SEC101/Teacher/Lessons/Audionotes/target\"\n",
    "\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "            input_file = os.path.join(root, file)\n",
    "            output_file = os.path.join(output_dir, file)\n",
    "            print(input_file)\n",
    "            # Appliquez SOX pour débruiter le fichier audio\n",
    "            subprocess.call([\"sox\", input_file, output_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/bark is already downloaded.\n",
      " > Using model: bark\n",
      " > Text splitted to sentences.\n",
      "['Wie sage ich auf Italienisch, dass ich dich liebe?']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.95it/s]\n",
      "100%|██████████| 9/9 [00:43<00:00,  4.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 67.14357113838196\n",
      " > Real-time factor: 15.885362055808178\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": " [!] Model file not found in the output path",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/fcdw3504/Documents/GitHub/CYBERDEF101/IA-gen.ipynb Cellule 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fcdw3504/Documents/GitHub/CYBERDEF101/IA-gen.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mTTS\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m TTS\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fcdw3504/Documents/GitHub/CYBERDEF101/IA-gen.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tts \u001b[39m=\u001b[39m TTS(\u001b[39m\"\u001b[39m\u001b[39mtts_models/multilingual/multi-dataset/bark\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fcdw3504/Documents/GitHub/CYBERDEF101/IA-gen.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tts\u001b[39m.\u001b[39;49mtts_with_vc_to_file(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fcdw3504/Documents/GitHub/CYBERDEF101/IA-gen.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mWie sage ich auf Italienisch, dass ich dich liebe?\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fcdw3504/Documents/GitHub/CYBERDEF101/IA-gen.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     speaker_wav\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/Users/fcdw3504/Documents/GitHub/CYBERDEF101/Release/SEC101/Teacher/Lessons/Audionotes/sources/eric.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fcdw3504/Documents/GitHub/CYBERDEF101/IA-gen.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     file_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/Users/fcdw3504/Documents/GitHub/CYBERDEF101/Release/SEC101/Teacher/Lessons/Audionotes/target/output.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fcdw3504/Documents/GitHub/CYBERDEF101/IA-gen.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/TTS/api.py:475\u001b[0m, in \u001b[0;36mTTS.tts_with_vc_to_file\u001b[0;34m(self, text, language, speaker_wav, file_path)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtts_with_vc_to_file\u001b[39m(\n\u001b[1;32m    457\u001b[0m     \u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m, language: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, speaker_wav: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, file_path: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moutput.wav\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    458\u001b[0m ):\n\u001b[1;32m    459\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert text to speech with voice conversion and save to file.\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \n\u001b[1;32m    461\u001b[0m \u001b[39m    Check `tts_with_vc` for more details.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[39m            Output file path. Defaults to \"output.wav\".\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     wav \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtts_with_vc(text\u001b[39m=\u001b[39;49mtext, language\u001b[39m=\u001b[39;49mlanguage, speaker_wav\u001b[39m=\u001b[39;49mspeaker_wav)\n\u001b[1;32m    476\u001b[0m     save_wav(wav\u001b[39m=\u001b[39mwav, path\u001b[39m=\u001b[39mfile_path, sample_rate\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvoice_converter\u001b[39m.\u001b[39mvc_config\u001b[39m.\u001b[39maudio\u001b[39m.\u001b[39moutput_sample_rate)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/TTS/api.py:452\u001b[0m, in \u001b[0;36mTTS.tts_with_vc\u001b[0;34m(self, text, language, speaker_wav)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtts_to_file(text\u001b[39m=\u001b[39mtext, speaker\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, language\u001b[39m=\u001b[39mlanguage, file_path\u001b[39m=\u001b[39mfp\u001b[39m.\u001b[39mname)\n\u001b[1;32m    451\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvoice_converter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 452\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_vc_model_by_name(\u001b[39m\"\u001b[39;49m\u001b[39mvoice_conversion_models/multilingual/vctk/freevc24\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    453\u001b[0m wav \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvoice_converter\u001b[39m.\u001b[39mvoice_conversion(source_wav\u001b[39m=\u001b[39mfp\u001b[39m.\u001b[39mname, target_wav\u001b[39m=\u001b[39mspeaker_wav)\n\u001b[1;32m    454\u001b[0m \u001b[39mreturn\u001b[39;00m wav\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/TTS/api.py:160\u001b[0m, in \u001b[0;36mTTS.load_vc_model_by_name\u001b[0;34m(self, model_name, gpu)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load one of the voice conversion models by name.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \n\u001b[1;32m    155\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m    model_name (str): Model name to load. You can list models by ```tts.models```.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m    gpu (bool, optional): Enable/disable GPU. Some models might be too slow on CPU. Defaults to False.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name \u001b[39m=\u001b[39m model_name\n\u001b[0;32m--> 160\u001b[0m model_path, config_path, _, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_model_by_name(model_name)\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvoice_converter \u001b[39m=\u001b[39m Synthesizer(vc_checkpoint\u001b[39m=\u001b[39mmodel_path, vc_config\u001b[39m=\u001b[39mconfig_path, use_cuda\u001b[39m=\u001b[39mgpu)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/TTS/api.py:142\u001b[0m, in \u001b[0;36mTTS.download_model_by_name\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload_model_by_name\u001b[39m(\u001b[39mself\u001b[39m, model_name: \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     model_path, config_path, model_item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmanager\u001b[39m.\u001b[39;49mdownload_model(model_name)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfairseq\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_name \u001b[39mor\u001b[39;00m (model_item \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(model_item[\u001b[39m\"\u001b[39m\u001b[39mmodel_url\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mlist\u001b[39m)):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# return model directory if there are multiple files\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39m# we assume that the model knows how to load itself\u001b[39;00m\n\u001b[1;32m    146\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, model_path\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/TTS/utils/manage.py:369\u001b[0m, in \u001b[0;36mModelManager.download_model\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m    365\u001b[0m output_config_path \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    367\u001b[0m     model \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mtortoise-v2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbark\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mxtts_v1\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfairseq\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m model_name\n\u001b[1;32m    368\u001b[0m ):  \u001b[39m# TODO:This is stupid but don't care for now.\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     output_model_path, output_config_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_files(output_path)\n\u001b[1;32m    370\u001b[0m \u001b[39m# update paths in the config.json\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_paths(output_path, output_config_path)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/TTS/utils/manage.py:392\u001b[0m, in \u001b[0;36mModelManager._find_files\u001b[0;34m(output_path)\u001b[0m\n\u001b[1;32m    390\u001b[0m         config_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_path, file_name)\n\u001b[1;32m    391\u001b[0m \u001b[39mif\u001b[39;00m model_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 392\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m [!] Model file not found in the output path\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    393\u001b[0m \u001b[39mif\u001b[39;00m config_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    394\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m [!] Config file not found in the output path\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m:  [!] Model file not found in the output path"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/bark\")\n",
    "tts.tts_with_vc_to_file(\n",
    "    \"Wie sage ich auf Italienisch, dass ich dich liebe?\",\n",
    "    speaker_wav=\"/Users/fcdw3504/Documents/GitHub/CYBERDEF101/Release/SEC101/Teacher/Lessons/Audionotes/sources/eric.wav\",\n",
    "    file_path=\"/Users/fcdw3504/Documents/GitHub/CYBERDEF101/Release/SEC101/Teacher/Lessons/Audionotes/target/output.wav\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
